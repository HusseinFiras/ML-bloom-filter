import mmh3
import math
import requests
import pandas as pd
import tldextract
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from urllib.parse import urlparse


# Counting Bloom Filter setup
n = 10000  # Number of expected URLs to store
P = 0.01  # Desired false positive rate
m = -int((n * math.log(P)) / (math.log(2) ** 2))  # Size of the array
k = int((m / n) * math.log(2))  # Number of hash functions
counters = [0] * m

def add_url(url):
    for seed in range(k):
        index = mmh3.hash(url, seed) % m
        counters[index] += 1



def is_malicious(url):
    for seed in range(k):
        index = mmh3.hash(url, seed) % m
        if counters[index] == 0:
            return False
    return True
# Load the malicious URLs from a text file.
def load_malicious_urls(file_path):
  with open(file_path, 'r') as file:
        for line in file:
            url = line.strip()
            add_url(url)

load_malicious_urls('original_dataset.txt')

# Google Safe Browsing API Key Placeholder
api_key = "AIzaSyBEDFMqWqjhTMOmImUmjr2zcxfN3_3ufiU"  

def check_url_with_google_safe_browsing(url, api_key):
    api_url = "https://safebrowsing.googleapis.com/v4/threatMatches:find"
    payload = {
        "client": {
            "clientId": "bloomfilter",
            "clientVersion": "1.5.2"
        },
        "threatInfo": {
            "threatTypes": ["MALWARE", "SOCIAL_ENGINEERING"],
            "platformTypes": ["ANY_PLATFORM"],
            "threatEntryTypes": ["URL"],
            "threatEntries": [{"url": url}]
        }
    }
    params = {"key": api_key}
    response = requests.post(api_url, json=payload, params=params)
    data = response.json()
    return "unsafe" if "matches" in data else "safe"

def normalize_url(url):
    url = url.lower().strip()
    if url.startswith("http://"):
        url = url[7:]
    elif url.startswith("https://"):
        url = url[8:]
    if url.startswith("www."):
        url = url[4:]
    url = url.rstrip('/')
    return url

def extract_features(urls):
    features = pd.DataFrame()
    urls = urls.apply(normalize_url)
    features['num_special_chars'] = urls.apply(lambda x: sum(not c.isalnum() for c in x))
    parsed_urls = urls.apply(urlparse)
    features['count_dir'] = parsed_urls.apply(lambda x: x.path.count('/'))
    features['uses_https'] = parsed_urls.apply(lambda x: x.scheme == 'https')
    features['count_digits'] = urls.apply(lambda x: sum(c.isdigit() for c in x))
    features['hostname_length'] = parsed_urls.apply(lambda x: len(x.netloc))
    features['path_length'] = parsed_urls.apply(lambda x: len(x.path))
    tld_lengths = urls.apply(lambda x: len(tldextract.extract(x).suffix))
    features['tld_length'] = tld_lengths
    return features

# Read data
df = pd.read_csv('filtered_malicious_phish.csv').head(652190)  # Adjust path as needed

# Extract features and labels
X = extract_features(df['url'])
y = df['type']

# Split and train model
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Evaluate model
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

def classify_new_url(new_url, clf, extract_features, api_key):
    normalized_url = normalize_url(new_url)
    # Check with Bloom Filter first for efficiency
    if is_malicious(normalized_url):
        return 'Potential phishing or malware (Bloom Filter)'  # Indicating it's caught by the Bloom Filter

    # Check with Google Safe Browsing API
    safety_status = check_url_with_google_safe_browsing(normalized_url, api_key)
    if safety_status == "unsafe":
        return 'Unsafe according to Google Safe Browsing'

    # Extract features and classify with the ML model
    new_features = extract_features(pd.Series([normalized_url]))
    predicted_class = clf.predict(new_features)
    return predicted_class[0]  # Return the predicted class directly




def check_url(url, clf, extract_features, api_key):
    print("Checking URL in the Counting Bloom Filter dataset...")
    if is_malicious(url):
        print(f"The URL '{url}' is potentially malicious according to the Bloom Filter.")
    else:
        print("URL not found in the Counting Bloom Filter dataset. Proceeding with detailed analysis...")
        prediction = classify_new_url(url, clf, extract_features, api_key)
        print(f"The URL '{url}' is classified as '{prediction}'.")


# Interactive URL classification
def predict_multiple_urls(api_key, clf, extract_features):
    print("Enter URLs to classify, or type 'exit' to quit:")
    while True:
        new_url = input("URL: ")
        if new_url.lower() == 'exit':
            break
        check_url(new_url, clf, extract_features, api_key)

predict_multiple_urls(api_key, clf, extract_features)